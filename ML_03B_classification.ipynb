{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "tN-01XtgEdtC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9J0k2nJEdtD"
      },
      "source": [
        "## 3. Логистическая регрессия. Реализация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vJRrOEREdtO"
      },
      "source": [
        "Функция ошибки для логистической регрессии в случае бинарной классификации называется бинарной кросс-энтропией и записывается следующим образом:\n",
        "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i))),$$\n",
        "где $x_i$ — вектор признаков $i$-го примера из обучающей выборки, $y_i$ — истинный класс для соответствующего примера (0 или 1), $n$ — число примеров в обучающей выборке, $h_{\\theta}(x)$ — sigmoid функция, равная:\n",
        "$$h_{\\theta}(x)=\\frac{1}{1+\\exp^{-\\theta x}},$$\n",
        "где $\\theta$ — вектор параметров логистической регрессии, $x$ - вектор признаков объекта из выборки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPJIyl-9EdtP"
      },
      "source": [
        "Соответствующий градиент функции ошибки равен:\n",
        "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3eYW2GAEdtP"
      },
      "source": [
        "Реализация логистической регрессии будет основана на оптимизации функции ошибки градиентным спуском."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEP_VxGmEdtQ"
      },
      "source": [
        "В качестве экспериментальных данных возьмем датасет о доходах граждан в различных странах [Adult Income](https://archive.ics.uci.edu/ml/datasets/Adult) и сделаем необходимую предобработку."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMB0qM7EEdtQ"
      },
      "outputs": [],
      "source": [
        "adult = pd.read_csv('./data/adult.data',\n",
        "                    names=['age', 'workclass', 'fnlwgt', 'education',\n",
        "                           'education-num', 'marital-status', 'occupation',\n",
        "                           'relationship', 'race', 'sex', 'capital-gain',\n",
        "                           'capital-loss', 'hours-per-week', 'native-country', 'salary'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBf7vMPyEdtQ"
      },
      "outputs": [],
      "source": [
        "# Описание датасета\n",
        "\n",
        "# with open('./data/adult.names', 'r') as f:\n",
        "#     names = f.read()\n",
        "# print(names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5AdMTEkEdtR"
      },
      "outputs": [],
      "source": [
        "adult.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCNy6Ab_EdtR"
      },
      "outputs": [],
      "source": [
        "# Избавиться от лишних признаков\n",
        "adult.drop(['native-country'], axis=1, inplace=True)\n",
        "# Сконвертировать целевой столбец в бинарные значения\n",
        "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
        "# Сделать one-hot encoding для некоторых признаков\n",
        "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d3XPDLoEdtR"
      },
      "outputs": [],
      "source": [
        "adult.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djkCSv_fEdtS"
      },
      "outputs": [],
      "source": [
        "# Нормализовать нуждающиеся в этом признаки\n",
        "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
        "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
        "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF8oaKS7EdtS"
      },
      "outputs": [],
      "source": [
        "adult.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTZWTHivEdtS"
      },
      "outputs": [],
      "source": [
        "# Разбить таблицу данных на матрицы X и y\n",
        "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
        "y = adult['salary'].values\n",
        "\n",
        "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
        "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
        "m = X.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLtumLTdEdtT"
      },
      "outputs": [],
      "source": [
        "# Реализовать функцию sigmoid\n",
        "def sigmoid(X, theta):\n",
        "    return 1. / (1. + np.exp(-X.dot(theta)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2rQQNapEdtT"
      },
      "outputs": [],
      "source": [
        "# Реализовать функцию, вычисляющую градиент бинарной кросс-энтропии\n",
        "def calc_binary_cross_entropy_grad(X, y, theta):\n",
        "    n = X.shape[0]\n",
        "    grad = 1. / n * X.transpose().dot(sigmoid(X, theta) - y)\n",
        "    \n",
        "    return grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCSaSLVfEdtU"
      },
      "outputs": [],
      "source": [
        "def gradient_step(theta, theta_grad, alpha):\n",
        "    return theta - alpha * theta_grad\n",
        "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
        "    theta = start_theta.copy()\n",
        "    \n",
        "    for i in range(n_iters):\n",
        "        theta_grad = grad_func(X, y, theta)\n",
        "        theta = gradient_step(theta, theta_grad, alpha)\n",
        "    \n",
        "    return theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcLW5uZyEdtU"
      },
      "outputs": [],
      "source": [
        "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
        "theta = optimize(X, y, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9r0dmh9MEdtU"
      },
      "outputs": [],
      "source": [
        "theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIb0VgQFEdtV"
      },
      "outputs": [],
      "source": [
        "def print_logisitc_metrics(y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f'acc = {acc:.2f} F1-score = {f1:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BWIkYOlEdtV"
      },
      "outputs": [],
      "source": [
        "# Сделать предсказания на тренировочной выборке и\n",
        "# посчитать значение метрики accuracy и F1-score\n",
        "y_pred = sigmoid(X, theta) > 0.5\n",
        "print_logisitc_metrics(y, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQfw6AUKEdtV"
      },
      "outputs": [],
      "source": [
        "# Разбить выборку на train/valid, оптимизировать theta,\n",
        "# сделать предсказания и посчитать ошибку F1-score\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
        "theta = optimize(X_train, y_train, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)\n",
        "y_pred = sigmoid(X_valid, theta) > 0.5\n",
        "\n",
        "print_logisitc_metrics(y_valid, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z7nMecbEdtV"
      },
      "outputs": [],
      "source": [
        "# Отрисовать ROC кривую\n",
        "def calc_and_plot_roc(y_true, y_pred_proba):\n",
        "    # Посчитать значения ROC кривой и значение площади под кривой AUC\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "    \n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "    plt.title('Receiver Operating Characteristic', fontsize=15)\n",
        "    plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
        "    plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
        "    plt.legend(fontsize=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1RZHBa9EdtW"
      },
      "outputs": [],
      "source": [
        "# Вычислить вероятности принадлежности классу 1 для каждого объекта из валидационной выборки\n",
        "y_pred_proba = sigmoid(X_valid, theta)\n",
        "calc_and_plot_roc(y_valid, y_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTyqDypAEdtW"
      },
      "source": [
        "## 4. Добавление регуляризации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TxJIRyqEdtW"
      },
      "source": [
        "### 4.1. Оборачивание линейной регрессии в класс"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXl0EH7sEdtW"
      },
      "outputs": [],
      "source": [
        "class RegOptimizer():\n",
        "    def __init__(self, alpha, n_iters):\n",
        "        self.theta = None\n",
        "        self._alpha = alpha\n",
        "        self._n_iters = n_iters\n",
        "    \n",
        "    def gradient_step(self, theta, theta_grad):\n",
        "        return theta - self._alpha * theta_grad\n",
        "    \n",
        "    def grad_func(self, X, y, theta):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def optimize(self, X, y, start_theta, n_iters):\n",
        "        theta = start_theta.copy()\n",
        "\n",
        "        for _ in range(n_iters):\n",
        "            theta_grad = self.grad_func(X, y, theta)\n",
        "            theta = self.gradient_step(theta, theta_grad)\n",
        "\n",
        "        return theta\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        m = X.shape[1]\n",
        "        start_theta = np.ones(m)\n",
        "        self.theta = self.optimize(X, y, start_theta, self._n_iters)\n",
        "        \n",
        "    def predict(self, X):\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZV-CxhsEdtX"
      },
      "outputs": [],
      "source": [
        "class LinReg(RegOptimizer):\n",
        "    def grad_func(self, X, y, theta):\n",
        "        n = X.shape[0]\n",
        "        grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
        "\n",
        "        return grad\n",
        "    \n",
        "    def predict(self, X):\n",
        "        if self.theta is None:\n",
        "            raise Exception('You should train the model first')\n",
        "        \n",
        "        y_pred = X.dot(self.theta)\n",
        "        \n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8hFV_h4EdtX"
      },
      "outputs": [],
      "source": [
        "def print_regression_metrics(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n",
        "def prepare_boston_data():\n",
        "    data = load_boston()\n",
        "    X, y = data['data'], data['target']\n",
        "    # Нормализовать даннные с помощью стандартной нормализации\n",
        "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
        "    X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
        "    \n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qevL0WpaEdtX"
      },
      "outputs": [],
      "source": [
        "linreg = LinReg(0.01, 500)\n",
        "X, y = prepare_boston_data()\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgmqMu2hEdtX"
      },
      "outputs": [],
      "source": [
        "linreg.fit(X_train, y_train)\n",
        "y_pred = linreg.predict(X_valid)\n",
        "print_regression_metrics(y_valid, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A_6GEY7EdtX"
      },
      "source": [
        "### 4.2. Оборачивание логистической регрессии в класс"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHMIrpCeEdtY"
      },
      "outputs": [],
      "source": [
        "class LogReg(RegOptimizer):\n",
        "    def sigmoid(self, X, theta):\n",
        "        return 1. / (1. + np.exp(-X.dot(theta)))\n",
        "    \n",
        "    def grad_func(self, X, y, theta):\n",
        "        n = X.shape[0]\n",
        "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, theta) - y)\n",
        "\n",
        "        return grad\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        return self.sigmoid(X, self.theta)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        if self.theta is None:\n",
        "            raise Exception('You should train the model first')\n",
        "        \n",
        "        y_pred = self.predict_proba(X) > 0.5\n",
        "        \n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxQpbi7xEdtY"
      },
      "outputs": [],
      "source": [
        "def prepare_adult_data():\n",
        "    adult = pd.read_csv('./data/adult.data',\n",
        "                        names=['age', 'workclass', 'fnlwgt', 'education',\n",
        "                               'education-num', 'marital-status', 'occupation',\n",
        "                               'relationship', 'race', 'sex', 'capital-gain',\n",
        "                               'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
        "    \n",
        "    # Избавиться от лишних признаков\n",
        "    adult.drop(['native-country'], axis=1, inplace=True)\n",
        "    # Сконвертировать целевой столбец в бинарные значения\n",
        "    adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
        "    # Сделать one-hot encoding для некоторых признаков\n",
        "    adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])\n",
        "    \n",
        "    # Нормализовать нуждающиеся в этом признаки\n",
        "    a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
        "    norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
        "    adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
        "    \n",
        "    # Разбить таблицу данных на матрицы X и y\n",
        "    X = adult[list(set(adult.columns) - set(['salary']))].values\n",
        "    y = adult['salary'].values\n",
        "\n",
        "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
        "    X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
        "    \n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk3T1yRdEdtY"
      },
      "outputs": [],
      "source": [
        "logreg = LogReg(1., 300)\n",
        "X, y = prepare_adult_data()\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxM4N82UEdtY"
      },
      "outputs": [],
      "source": [
        "# Разбить выборку на train/valid, оптимизировать theta,\n",
        "# сделать предсказания и посчитать ошибку F1-score\n",
        "\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_valid)\n",
        "\n",
        "print_logisitc_metrics(y_valid, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXg55qO0EdtZ"
      },
      "outputs": [],
      "source": [
        "y_pred_proba = logreg.predict_proba(X_valid)\n",
        "calc_and_plot_roc(y_valid, y_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaSXAXkxEdtZ"
      },
      "source": [
        "В случаях линейной и логистической регрессии будем добавлять к функции ошибки регуляризующую часть как:\n",
        "$$\\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2},$$\n",
        "где $\\theta$ — вектор параметров линейной модели без фиктивного признака (intercept/bias term), $m$ — количество нефиктивных признаков, $\\lambda$ — параметр регуляризации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BePDE-iwEdtZ"
      },
      "source": [
        "### 4.3. Добавление регуляризатора в линейную регрессию"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U87vO1oLEdtZ"
      },
      "source": [
        "После добавления регуляризации функция ошибки линейной регрессии будет выглядеть следующим образом:\n",
        "$$L=\\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2} + \\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2}$$\n",
        "А ее градиент по параметру $\\theta$:\n",
        "$$\\nabla L = \\frac{1}{n}\\sum_{i=1}^{n}{(\\theta^Tx_i - y_i) \\cdot x_i} + \\frac{\\lambda}{m}\\sum_{j=1}^{m}{\\theta_j} = \\frac{1}{n}X^T(X\\theta - y) + \\frac{\\lambda}{m}\\sum_{j=1}^{m}{\\theta_j}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpCV96VfEdtZ"
      },
      "outputs": [],
      "source": [
        "class LinRegRegularized(LinReg):\n",
        "    def __init__(self, alpha, lambd, n_iters):\n",
        "        super(LinRegRegularized, self).__init__(alpha, n_iters)\n",
        "        self._lambd = lambd\n",
        "    \n",
        "    def grad_func(self, X, y, theta):\n",
        "        n = X.shape[0]\n",
        "        grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
        "        grad_term = self._lambd * np.mean(theta)\n",
        "\n",
        "        return grad + grad_term"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abbDP3qAEdta"
      },
      "outputs": [],
      "source": [
        "linreg = LinRegRegularized(alpha=0.01, lambd=0.05, n_iters=500)\n",
        "X, y = prepare_boston_data()\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lJtCA7YEdta"
      },
      "outputs": [],
      "source": [
        "linreg.fit(X_train, y_train)\n",
        "y_pred = linreg.predict(X_valid)\n",
        "print_regression_metrics(y_valid, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRBjIFGxEdta"
      },
      "source": [
        "### 4.4. Добавление регуляризатора в логистическую регрессию"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYwPhu7HEdta"
      },
      "source": [
        "Функция ошибки для логистической регрессии в случае бинарной классификации с регуляризатором записывается следующим образом:\n",
        "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i)))+\\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2},$$\n",
        "где $x_i$ — вектор признаков $i$-го примера из обучающей выборки, $y_i$ — истинный класс для соответствующего примера (0 или 1), $n$ — число примеров в обучающей выборке, $m$ — количество нефиктивных признаков, $\\lambda$ — параметр регуляризации, $h_{\\theta}(x)$ — sigmoid функция, равная:\n",
        "$$h_{\\theta}(x)=\\frac{1}{1+\\exp^{-\\theta x}},$$\n",
        "где $\\theta$ — вектор параметров логистической регрессии, $x$ - вектор признаков объекта из выборки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T7zklPVEdta"
      },
      "source": [
        "Соответствующий градиент функции ошибки равен:\n",
        "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}+\\frac{\\lambda}{m}\\sum_{j}^{m}{\\theta_j}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLNhE0UkEdta"
      },
      "outputs": [],
      "source": [
        "class LogRegRegularized(LogReg):\n",
        "    def __init__(self, alpha, lambd, n_iters):\n",
        "        super(LogRegRegularized, self).__init__(alpha, n_iters)\n",
        "        self._lambd = lambd\n",
        "    \n",
        "    def grad_func(self, X, y, theta):\n",
        "        n = X.shape[0]\n",
        "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, theta) - y)\n",
        "        grad_term = self._lambd * np.mean(theta)\n",
        "\n",
        "        return grad + grad_term"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgW1EPGiEdtb"
      },
      "outputs": [],
      "source": [
        "logreg = LogRegRegularized(alpha=1., lambd=1., n_iters=300)\n",
        "X, y = prepare_adult_data()\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDFwObH0Edtb"
      },
      "outputs": [],
      "source": [
        "# Разбить выборку на train/valid, оптимизировать theta,\n",
        "# сделать предсказания и посчитать ошибку F1-score\n",
        "\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_valid)\n",
        "\n",
        "print_logisitc_metrics(y_valid, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "ieAHSzCoEdtb"
      },
      "outputs": [],
      "source": [
        "y_pred_proba = logreg.predict_proba(X_valid)\n",
        "calc_and_plot_roc(y_valid, y_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задания - ML-3B. Классификация"
      ],
      "metadata": {
        "id": "Gwv_49RFEqEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "I8eoBtV6E484"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwdYhoUhEdtb",
        "outputId": "36af4321-4423-4a37-bfa7-8c6c3ea1e9c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3434070875143007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in log\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in multiply\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# ML-3B. Классификация  6. Логистическая регрессия. Часть II\n",
        "\n",
        "# Задание 5.3\n",
        "\n",
        "# Посчитайте  для данных в таблице (без нормализации). Укажите число с точностью до сотых:\n",
        "y_pred = np.array([0.2,\t0.8,\t1,\t0.6])\n",
        "y_true = np.array([0, 0,\t1,\t1])\n",
        "print(np.nansum(-y_true*np.log(y_pred) - (1-y_true)*np.log(1-y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "real = [0,0,1,1]\n",
        "pred = [0.2, 0.8, 1.0, 0.6]\n",
        "log_loss(real, pred, normalize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68CCVqGoE0Xj",
        "outputId": "f296f227-2948-4e76-a9fc-42839b398da4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.343407087514302"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задание 5.4\n",
        "# Посчитайте  для данных в таблице. Необходимо найти среднюю ошибку. Классификация на три класса:\n",
        "\n",
        "pred = np.array([[0.2, 0.3, 0.5],  # probability of being in each of 3 classes\n",
        "                 [0, 0, 1], \n",
        "                 [0.1, 0, 0.9]\n",
        "                 ])\n",
        "y = np.array([[0, 0, 1],   # each row a three class classification\n",
        "              [0, 0, 1],\n",
        "              [1, 0, 0]\n",
        "              ])\n",
        "\n",
        "observations_num = y.shape[0]\n",
        "classes_num = y.shape[1]\n",
        "multi_logloss = 0\n",
        "for i in range(observations_num):\n",
        "    for j in range(classes_num):\n",
        "        multi_logloss += np.nansum(y[i][j] * np.log(pred[i][j]))\n",
        "ave_multi_logloss = (-1/observations_num)*multi_logloss\n",
        "print(round(ave_multi_logloss, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzMMacutE3-v",
        "outputId": "3cbc5d99-0427-4c6e-8622-edbac471d530"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in multiply\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задание 6.1\n",
        "\n",
        "# Постройте модель логистической регрессии при помощи sklearn. Используйте параметры по \n",
        "# умолчанию, обучите на всей выборке и посчитайте F1 score.\n",
        "\n",
        "# Ответ округлите до сотых. Пример ввода: 5.55.\n",
        "\n",
        "# *Если вы всё правильно посчитали, но система не принимает ваш ответ, \n",
        "# попробуйте другую версию sklearn.\n",
        "import pandas as pd\n",
        "\n",
        "adult = pd.read_csv(\n",
        "    'adult.data',\n",
        "    names=['age', 'workclass', 'fnlwgt', 'education',\n",
        "           'education-num', 'marital-status', 'occupation',\n",
        "           'relationship', 'race', 'sex', 'capital-gain',\n",
        "           'capital-loss', 'hours-per-week', 'native-country', 'salary'\n",
        "           ])"
      ],
      "metadata": {
        "id": "pibZCZMBE-XK"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Избавиться от лишних признаков\n",
        "adult.drop(['native-country'], axis=1, inplace=True)\n",
        "# Сконвертировать целевой столбец в бинарные значения\n",
        "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
        "# Сделать one-hot encoding для некоторых признаков\n",
        "adult = pd.get_dummies(\n",
        "    adult, \n",
        "    columns=['workclass', 'education', 'marital-status', \n",
        "             'occupation', 'relationship', 'race', 'sex'\n",
        "             ])\n",
        "\n",
        "# Нормализовать признаки\n",
        "feat = ['age', 'education-num', 'hours-per-week', \n",
        "        'fnlwgt', 'capital-gain', 'capital-loss']\n",
        "a_features = adult[feat].values\n",
        "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
        "adult.loc[:, feat] = norm_features\n",
        "\n",
        "# Разбить таблицу данных на матрицы X и y\n",
        "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
        "y = adult['salary'].values\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnNNuugHIxjm",
        "outputId": "d4f3db2f-032b-4b96-aa09-fc065eda28b4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32561, 66) (32561,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "P9xcw5JNJ2Sc"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression().fit(X, y)\n",
        "y_pred = clf.predict(X)\n",
        "\n",
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdbpanXoK9v7",
        "outputId": "d6ea4b81-6aa1-496e-ee0a-07c378bee8c2"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32561,)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(round(f1_score(y, y_pred), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMp9WLVFLYFj",
        "outputId": "45ed6ff0-26db-4cc1-f4f3-17d6815a46a0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VzFxdqJLlOU",
        "outputId": "9691ad8a-cd6f-47ea-b2b1-5ec37b014ca1"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23030,  1690],\n",
              "       [ 3124,  4717]])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_neg = 0\n",
        "true_pos = 0\n",
        "false_neg = 0\n",
        "for i, j in zip(y, y_pred):\n",
        "    if i == j and i == 0:\n",
        "        true_neg += 1\n",
        "    elif i == j and i == 1:\n",
        "        true_pos += 1\n",
        "    elif i == 1 and j == 0:\n",
        "        false_neg += 1\n",
        "print('true_neg:', true_neg, 'true_pos', true_pos, 'false_neg', false_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbuVwqkVMgJs",
        "outputId": "dcbc423a-84d6-4c33-a58f-b5c90a989d46"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true_neg: 23030 true_pos 4717 false_neg 3124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_score = clf.predict_proba(X)\n",
        "print(prob_score.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-thJCfSN6o3",
        "outputId": "0d7238a5-825c-46f9-c288-ec468e1c47b1"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32561, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(round(roc_auc_score(y, prob_score[:, 1]), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja5wkEWsPiDe",
        "outputId": "fbdc6545-8689-4f00-eb93-41759817e079"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задание 6.4\n",
        "# Переберите коэффициенты L2-регуляризации от 0.01 до 1 с шагом 0.01 и определите, на каком из \n",
        "# них модель логистической регрессии из sklearn даёт наибольший  F1.\n",
        "\n",
        "# Ответ округлите до сотых. \n",
        "c_val = np.arange(0.01, 1, 0.01)\n",
        "f1_scores = []\n",
        "# for c in c_val:\n",
        "#     clf = LogisticRegression(penalty='l2', C=c).fit(X, y)\n",
        "#     y_pred = clf.predict(X)\n",
        "#     f1_scores.append(f1_score(y, y_pred))"
      ],
      "metadata": {
        "id": "Ey60TJMRZh-r"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_val[np.array(f1_scores).argmax()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOGEuaDTbXcZ",
        "outputId": "6f471d22-e8c2-43a0-ceca-ec52d787df24"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.88"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(f1_scores).argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKJnXgembkzV",
        "outputId": "6034f8d6-2b3f-4c34-bff2-5d45c0fc679d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задание 6.5\n",
        "# Замените в столбце native-country страны, у которых меньше ста записей, на other, \n",
        "# поменяйте этот столбец на dummy-переменные, обучите классификатор на всей выборке \n",
        "# и посчитайте  F1.\n",
        "# Ответ округлите до сотых. Пример ввода: 5.55.\n",
        "\n",
        "adult = pd.read_csv(\n",
        "    'adult.data',\n",
        "    names=['age', 'workclass', 'fnlwgt', 'education',\n",
        "           'education-num', 'marital-status', 'occupation',\n",
        "           'relationship', 'race', 'sex', 'capital-gain',\n",
        "           'capital-loss', 'hours-per-week', 'native-country', 'salary'\n",
        "           ])"
      ],
      "metadata": {
        "id": "goCICRyQPrSz"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "country_counts = adult['native-country'].value_counts()\n",
        "for country in country_counts.index:\n",
        "    if country_counts[country] < 100:\n",
        "        adult.loc[adult['native-country'] == country, 'native-country'] = 'other'\n",
        "\n",
        "adult['native-country'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hjtb2PlRRWKX",
        "outputId": "8fee4038-9e66-4fed-dce7-efd67d4ea83c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " United-States    29170\n",
              "other              1389\n",
              " Mexico             643\n",
              " ?                  583\n",
              " Philippines        198\n",
              " Germany            137\n",
              " Canada             121\n",
              " Puerto-Rico        114\n",
              " El-Salvador        106\n",
              " India              100\n",
              "Name: native-country, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adult.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "VBoR9bjeYdah",
        "outputId": "ff2a6193-0846-4acd-cb83-8b407deb8374"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>other</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age          workclass  fnlwgt  ... hours-per-week  native-country  salary\n",
              "0   39          State-gov   77516  ...             40   United-States   <=50K\n",
              "1   50   Self-emp-not-inc   83311  ...             13   United-States   <=50K\n",
              "2   38            Private  215646  ...             40   United-States   <=50K\n",
              "3   53            Private  234721  ...             40   United-States   <=50K\n",
              "4   28            Private  338409  ...             40           other   <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сконвертировать целевой столбец в бинарные значения\n",
        "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
        "# Сделать one-hot encoding для некоторых признаков\n",
        "adult = pd.get_dummies(\n",
        "    adult, \n",
        "    columns=['workclass', 'education', 'marital-status', \n",
        "             'occupation', 'relationship', 'race', 'sex',\n",
        "             'native-country'\n",
        "             ])\n",
        "\n",
        "# Нормализовать признаки\n",
        "feat = ['age', 'education-num', 'hours-per-week', \n",
        "        'fnlwgt', 'capital-gain', 'capital-loss']\n",
        "\n",
        "a_features = adult[feat].values\n",
        "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
        "adult.loc[:, feat] = norm_features\n",
        "\n",
        "# Разбить таблицу данных на матрицы X и y\n",
        "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
        "y = adult['salary'].values\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaEvOJoaRVQ1",
        "outputId": "5f40fd5d-9ec8-4213-ed27-c4d9a487851c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32561, 76) (32561,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression().fit(X, y)\n",
        "y_pred = clf.predict(X)\n",
        "\n",
        "print(round(f1_score(y, y_pred), 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSlVYRvkVYw-",
        "outputId": "71f33403-6f48-440e-fff0-872c141ac868"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Курс  02 - Математика и алгоритмы для машинного обучения  ML-3B. \n",
        "# Классификация  8. Метрики качества классификации\n",
        "\n",
        "# Задание 2.1\n",
        "\n",
        "# Вы создали классификатор, который разделяет экономические и политические новости на два разных \n",
        "# Telegram-канала, и теперь хотите проверить качество классификатора. За день вышло 15 \n",
        "# политических новостей и 20 экономических.\n",
        "# Ваш алгоритм из 15 политических новостей отметил 9 как экономические, \n",
        "#  из 20 экономических — 6 как политические.\n",
        "# Найдите метрику Accuracy.\n",
        "# Ответ округлите до сотых.\n",
        "\n",
        "round((6+14)/35, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F26x32SbZAhi",
        "outputId": "19debcb5-2820-4888-e2db-a039467d2140"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.57"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задание 2.2\n",
        "\n",
        "# Загрузите встроенный в библиотеку sklearn датасет про ирисы с помощью\n",
        "# функции load_iris. Обучите модель логистической регрессии (random_state=50, \n",
        "# размер тестовой выборки 0.3) и укажите полученное значение метрики Accuracy.\n",
        "# Ответ округлите до сотых.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=50)\n",
        "\n",
        "clf = LogisticRegression(random_state=50).fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5uNtMLyezBp",
        "outputId": "b3061ab7-08d7-4bd5-af94-9b811025d511"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI-_4Zs7gHi2",
        "outputId": "9983a975-6b63-43d1-8d57-c34ccc1b4442"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBmyCQ-xhRj1",
        "outputId": "c8a007c3-0c24-4f93-f964-d4f9a55a2a63"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45,)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu6enC2lkSKE",
        "outputId": "9ae5e13f-e383-406b-c225-53b9908fd75a"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 2, 2, 2, 0, 0, 1, 0, 2, 0, 2, 1, 0, 1, 0, 1, 1, 2, 1,\n",
              "       0, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 0, 0, 1, 2, 1, 0, 0, 1, 2, 0,\n",
              "       2])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hZjBazPiaHl",
        "outputId": "2fa4e1ea-2c72-4858-cdb1-3f6ff6ecca42"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14,  0,  0],\n",
              "       [ 0, 16,  1],\n",
              "       [ 0,  0, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# У вас есть датасет с параметрами мобильных телефонов. Переменная price_range отвечает за то, \n",
        "# к какой категории относится телефон: 1 — дорогие, 0 — дешевые.\n",
        "mob = pd.read_csv('train_mobile.csv', sep=';')\n",
        "print(mob.shape)\n",
        "mob.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "B4D_1ukqkYuM",
        "outputId": "2ca18231-b87f-479b-8768-853cecbf7673"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 21)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>pc</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "      <th>price_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842</td>\n",
              "      <td>0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>188</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>756</td>\n",
              "      <td>2549</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1021</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>0.7</td>\n",
              "      <td>136</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>905</td>\n",
              "      <td>1988</td>\n",
              "      <td>2631</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>563</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>0.9</td>\n",
              "      <td>145</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1263</td>\n",
              "      <td>1716</td>\n",
              "      <td>2603</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>615</td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0.8</td>\n",
              "      <td>131</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>1216</td>\n",
              "      <td>1786</td>\n",
              "      <td>2769</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1821</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>44</td>\n",
              "      <td>0.6</td>\n",
              "      <td>141</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>1208</td>\n",
              "      <td>1212</td>\n",
              "      <td>1411</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   battery_power  blue  clock_speed  ...  touch_screen  wifi  price_range\n",
              "0            842     0          2.2  ...             0     1            0\n",
              "1           1021     1          0.5  ...             1     0            1\n",
              "2            563     1          0.5  ...             1     0            1\n",
              "3            615     1          2.5  ...             0     0            1\n",
              "4           1821     1          1.2  ...             1     0            0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mob.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDydOUthoOER",
        "outputId": "95960590-c451-4cd5-9889-a9d3b2dd52ab"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "battery_power    0\n",
              "blue             0\n",
              "clock_speed      0\n",
              "dual_sim         0\n",
              "fc               0\n",
              "four_g           0\n",
              "int_memory       0\n",
              "m_dep            0\n",
              "mobile_wt        0\n",
              "n_cores          0\n",
              "pc               0\n",
              "px_height        0\n",
              "px_width         0\n",
              "ram              0\n",
              "sc_h             0\n",
              "sc_w             0\n",
              "talk_time        0\n",
              "three_g          0\n",
              "touch_screen     0\n",
              "wifi             0\n",
              "price_range      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mob.dtypes.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RASoVJsooSgE",
        "outputId": "20554193-e63b-40f3-b46c-f0c6a0057c9f"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([dtype('int64'), dtype('float64')], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mob.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "LZZaif0JojrX",
        "outputId": "3d9d7924-9f87-4699-babc-e9cd72911210"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_power</th>\n",
              "      <th>blue</th>\n",
              "      <th>clock_speed</th>\n",
              "      <th>dual_sim</th>\n",
              "      <th>fc</th>\n",
              "      <th>four_g</th>\n",
              "      <th>int_memory</th>\n",
              "      <th>m_dep</th>\n",
              "      <th>mobile_wt</th>\n",
              "      <th>n_cores</th>\n",
              "      <th>pc</th>\n",
              "      <th>px_height</th>\n",
              "      <th>px_width</th>\n",
              "      <th>ram</th>\n",
              "      <th>sc_h</th>\n",
              "      <th>sc_w</th>\n",
              "      <th>talk_time</th>\n",
              "      <th>three_g</th>\n",
              "      <th>touch_screen</th>\n",
              "      <th>wifi</th>\n",
              "      <th>price_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>battery_power</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.011252</td>\n",
              "      <td>0.011482</td>\n",
              "      <td>-0.041847</td>\n",
              "      <td>0.033334</td>\n",
              "      <td>0.015665</td>\n",
              "      <td>-0.004004</td>\n",
              "      <td>0.034085</td>\n",
              "      <td>0.001844</td>\n",
              "      <td>-0.029727</td>\n",
              "      <td>0.031441</td>\n",
              "      <td>0.014901</td>\n",
              "      <td>-0.008402</td>\n",
              "      <td>-0.000653</td>\n",
              "      <td>-0.029959</td>\n",
              "      <td>-0.021421</td>\n",
              "      <td>0.052510</td>\n",
              "      <td>0.011522</td>\n",
              "      <td>-0.010516</td>\n",
              "      <td>-0.008343</td>\n",
              "      <td>0.149402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>blue</th>\n",
              "      <td>0.011252</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.021419</td>\n",
              "      <td>0.035198</td>\n",
              "      <td>0.003593</td>\n",
              "      <td>0.013443</td>\n",
              "      <td>0.041177</td>\n",
              "      <td>0.004049</td>\n",
              "      <td>-0.008605</td>\n",
              "      <td>0.036161</td>\n",
              "      <td>-0.009952</td>\n",
              "      <td>-0.006872</td>\n",
              "      <td>-0.041533</td>\n",
              "      <td>0.026351</td>\n",
              "      <td>-0.002952</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>0.013934</td>\n",
              "      <td>-0.030236</td>\n",
              "      <td>0.010061</td>\n",
              "      <td>-0.021863</td>\n",
              "      <td>0.014001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clock_speed</th>\n",
              "      <td>0.011482</td>\n",
              "      <td>0.021419</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001315</td>\n",
              "      <td>-0.000434</td>\n",
              "      <td>-0.043073</td>\n",
              "      <td>0.006545</td>\n",
              "      <td>-0.014364</td>\n",
              "      <td>0.012350</td>\n",
              "      <td>-0.005724</td>\n",
              "      <td>-0.005245</td>\n",
              "      <td>-0.014523</td>\n",
              "      <td>-0.009476</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>-0.029078</td>\n",
              "      <td>-0.007378</td>\n",
              "      <td>-0.011432</td>\n",
              "      <td>-0.046433</td>\n",
              "      <td>0.019756</td>\n",
              "      <td>-0.024471</td>\n",
              "      <td>0.003494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dual_sim</th>\n",
              "      <td>-0.041847</td>\n",
              "      <td>0.035198</td>\n",
              "      <td>-0.001315</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.029123</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>-0.015679</td>\n",
              "      <td>-0.022142</td>\n",
              "      <td>-0.008979</td>\n",
              "      <td>-0.024658</td>\n",
              "      <td>-0.017143</td>\n",
              "      <td>-0.020875</td>\n",
              "      <td>0.014291</td>\n",
              "      <td>0.041072</td>\n",
              "      <td>-0.011949</td>\n",
              "      <td>-0.016666</td>\n",
              "      <td>-0.039404</td>\n",
              "      <td>-0.014008</td>\n",
              "      <td>-0.017117</td>\n",
              "      <td>0.022740</td>\n",
              "      <td>0.009002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fc</th>\n",
              "      <td>0.033334</td>\n",
              "      <td>0.003593</td>\n",
              "      <td>-0.000434</td>\n",
              "      <td>-0.029123</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.016560</td>\n",
              "      <td>-0.029133</td>\n",
              "      <td>-0.001791</td>\n",
              "      <td>0.023618</td>\n",
              "      <td>-0.013356</td>\n",
              "      <td>0.644595</td>\n",
              "      <td>-0.009990</td>\n",
              "      <td>-0.005176</td>\n",
              "      <td>0.015099</td>\n",
              "      <td>-0.011014</td>\n",
              "      <td>-0.012373</td>\n",
              "      <td>-0.006829</td>\n",
              "      <td>0.001793</td>\n",
              "      <td>-0.014828</td>\n",
              "      <td>0.020085</td>\n",
              "      <td>0.022464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>four_g</th>\n",
              "      <td>0.015665</td>\n",
              "      <td>0.013443</td>\n",
              "      <td>-0.043073</td>\n",
              "      <td>0.003187</td>\n",
              "      <td>-0.016560</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.008690</td>\n",
              "      <td>-0.001823</td>\n",
              "      <td>-0.016537</td>\n",
              "      <td>-0.029706</td>\n",
              "      <td>-0.005598</td>\n",
              "      <td>-0.019236</td>\n",
              "      <td>0.007448</td>\n",
              "      <td>0.007313</td>\n",
              "      <td>0.027166</td>\n",
              "      <td>0.037005</td>\n",
              "      <td>-0.046628</td>\n",
              "      <td>0.584246</td>\n",
              "      <td>0.016758</td>\n",
              "      <td>-0.017620</td>\n",
              "      <td>0.001001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>int_memory</th>\n",
              "      <td>-0.004004</td>\n",
              "      <td>0.041177</td>\n",
              "      <td>0.006545</td>\n",
              "      <td>-0.015679</td>\n",
              "      <td>-0.029133</td>\n",
              "      <td>0.008690</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.006886</td>\n",
              "      <td>-0.034214</td>\n",
              "      <td>-0.028310</td>\n",
              "      <td>-0.033273</td>\n",
              "      <td>0.010441</td>\n",
              "      <td>-0.008335</td>\n",
              "      <td>0.032813</td>\n",
              "      <td>0.037771</td>\n",
              "      <td>0.011731</td>\n",
              "      <td>-0.002790</td>\n",
              "      <td>-0.009366</td>\n",
              "      <td>-0.026999</td>\n",
              "      <td>0.006993</td>\n",
              "      <td>0.022132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m_dep</th>\n",
              "      <td>0.034085</td>\n",
              "      <td>0.004049</td>\n",
              "      <td>-0.014364</td>\n",
              "      <td>-0.022142</td>\n",
              "      <td>-0.001791</td>\n",
              "      <td>-0.001823</td>\n",
              "      <td>0.006886</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.021756</td>\n",
              "      <td>-0.003504</td>\n",
              "      <td>0.026282</td>\n",
              "      <td>0.025263</td>\n",
              "      <td>0.023566</td>\n",
              "      <td>-0.009434</td>\n",
              "      <td>-0.025348</td>\n",
              "      <td>-0.018388</td>\n",
              "      <td>0.017003</td>\n",
              "      <td>-0.012065</td>\n",
              "      <td>-0.002638</td>\n",
              "      <td>-0.028353</td>\n",
              "      <td>-0.018554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mobile_wt</th>\n",
              "      <td>0.001844</td>\n",
              "      <td>-0.008605</td>\n",
              "      <td>0.012350</td>\n",
              "      <td>-0.008979</td>\n",
              "      <td>0.023618</td>\n",
              "      <td>-0.016537</td>\n",
              "      <td>-0.034214</td>\n",
              "      <td>0.021756</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.018989</td>\n",
              "      <td>0.018844</td>\n",
              "      <td>0.000939</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>-0.002581</td>\n",
              "      <td>-0.033855</td>\n",
              "      <td>-0.020761</td>\n",
              "      <td>0.006209</td>\n",
              "      <td>0.001551</td>\n",
              "      <td>-0.014368</td>\n",
              "      <td>-0.000409</td>\n",
              "      <td>-0.007968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_cores</th>\n",
              "      <td>-0.029727</td>\n",
              "      <td>0.036161</td>\n",
              "      <td>-0.005724</td>\n",
              "      <td>-0.024658</td>\n",
              "      <td>-0.013356</td>\n",
              "      <td>-0.029706</td>\n",
              "      <td>-0.028310</td>\n",
              "      <td>-0.003504</td>\n",
              "      <td>-0.018989</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001193</td>\n",
              "      <td>-0.006872</td>\n",
              "      <td>0.024480</td>\n",
              "      <td>0.004868</td>\n",
              "      <td>-0.000315</td>\n",
              "      <td>0.025826</td>\n",
              "      <td>0.013148</td>\n",
              "      <td>-0.014733</td>\n",
              "      <td>0.023774</td>\n",
              "      <td>-0.009964</td>\n",
              "      <td>0.031260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pc</th>\n",
              "      <td>0.031441</td>\n",
              "      <td>-0.009952</td>\n",
              "      <td>-0.005245</td>\n",
              "      <td>-0.017143</td>\n",
              "      <td>0.644595</td>\n",
              "      <td>-0.005598</td>\n",
              "      <td>-0.033273</td>\n",
              "      <td>0.026282</td>\n",
              "      <td>0.018844</td>\n",
              "      <td>-0.001193</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.018465</td>\n",
              "      <td>0.004196</td>\n",
              "      <td>0.028984</td>\n",
              "      <td>0.004938</td>\n",
              "      <td>-0.023819</td>\n",
              "      <td>0.014657</td>\n",
              "      <td>-0.001322</td>\n",
              "      <td>-0.008742</td>\n",
              "      <td>0.005389</td>\n",
              "      <td>0.027628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>px_height</th>\n",
              "      <td>0.014901</td>\n",
              "      <td>-0.006872</td>\n",
              "      <td>-0.014523</td>\n",
              "      <td>-0.020875</td>\n",
              "      <td>-0.009990</td>\n",
              "      <td>-0.019236</td>\n",
              "      <td>0.010441</td>\n",
              "      <td>0.025263</td>\n",
              "      <td>0.000939</td>\n",
              "      <td>-0.006872</td>\n",
              "      <td>-0.018465</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.510664</td>\n",
              "      <td>-0.020352</td>\n",
              "      <td>0.059615</td>\n",
              "      <td>0.043038</td>\n",
              "      <td>-0.010645</td>\n",
              "      <td>-0.031174</td>\n",
              "      <td>0.021891</td>\n",
              "      <td>0.051824</td>\n",
              "      <td>0.097951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>px_width</th>\n",
              "      <td>-0.008402</td>\n",
              "      <td>-0.041533</td>\n",
              "      <td>-0.009476</td>\n",
              "      <td>0.014291</td>\n",
              "      <td>-0.005176</td>\n",
              "      <td>0.007448</td>\n",
              "      <td>-0.008335</td>\n",
              "      <td>0.023566</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.024480</td>\n",
              "      <td>0.004196</td>\n",
              "      <td>0.510664</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.004105</td>\n",
              "      <td>0.021599</td>\n",
              "      <td>0.034699</td>\n",
              "      <td>0.006720</td>\n",
              "      <td>0.000350</td>\n",
              "      <td>-0.001628</td>\n",
              "      <td>0.030319</td>\n",
              "      <td>0.116703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ram</th>\n",
              "      <td>-0.000653</td>\n",
              "      <td>0.026351</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>0.041072</td>\n",
              "      <td>0.015099</td>\n",
              "      <td>0.007313</td>\n",
              "      <td>0.032813</td>\n",
              "      <td>-0.009434</td>\n",
              "      <td>-0.002581</td>\n",
              "      <td>0.004868</td>\n",
              "      <td>0.028984</td>\n",
              "      <td>-0.020352</td>\n",
              "      <td>0.004105</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015996</td>\n",
              "      <td>0.035576</td>\n",
              "      <td>0.010820</td>\n",
              "      <td>0.015795</td>\n",
              "      <td>-0.030455</td>\n",
              "      <td>0.022669</td>\n",
              "      <td>0.822354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sc_h</th>\n",
              "      <td>-0.029959</td>\n",
              "      <td>-0.002952</td>\n",
              "      <td>-0.029078</td>\n",
              "      <td>-0.011949</td>\n",
              "      <td>-0.011014</td>\n",
              "      <td>0.027166</td>\n",
              "      <td>0.037771</td>\n",
              "      <td>-0.025348</td>\n",
              "      <td>-0.033855</td>\n",
              "      <td>-0.000315</td>\n",
              "      <td>0.004938</td>\n",
              "      <td>0.059615</td>\n",
              "      <td>0.021599</td>\n",
              "      <td>0.015996</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.506144</td>\n",
              "      <td>-0.017335</td>\n",
              "      <td>0.012033</td>\n",
              "      <td>-0.020023</td>\n",
              "      <td>0.025929</td>\n",
              "      <td>0.009140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sc_w</th>\n",
              "      <td>-0.021421</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>-0.007378</td>\n",
              "      <td>-0.016666</td>\n",
              "      <td>-0.012373</td>\n",
              "      <td>0.037005</td>\n",
              "      <td>0.011731</td>\n",
              "      <td>-0.018388</td>\n",
              "      <td>-0.020761</td>\n",
              "      <td>0.025826</td>\n",
              "      <td>-0.023819</td>\n",
              "      <td>0.043038</td>\n",
              "      <td>0.034699</td>\n",
              "      <td>0.035576</td>\n",
              "      <td>0.506144</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.022821</td>\n",
              "      <td>0.030941</td>\n",
              "      <td>0.012720</td>\n",
              "      <td>0.035423</td>\n",
              "      <td>0.035359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>talk_time</th>\n",
              "      <td>0.052510</td>\n",
              "      <td>0.013934</td>\n",
              "      <td>-0.011432</td>\n",
              "      <td>-0.039404</td>\n",
              "      <td>-0.006829</td>\n",
              "      <td>-0.046628</td>\n",
              "      <td>-0.002790</td>\n",
              "      <td>0.017003</td>\n",
              "      <td>0.006209</td>\n",
              "      <td>0.013148</td>\n",
              "      <td>0.014657</td>\n",
              "      <td>-0.010645</td>\n",
              "      <td>0.006720</td>\n",
              "      <td>0.010820</td>\n",
              "      <td>-0.017335</td>\n",
              "      <td>-0.022821</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.042688</td>\n",
              "      <td>0.017196</td>\n",
              "      <td>-0.029504</td>\n",
              "      <td>0.004394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>three_g</th>\n",
              "      <td>0.011522</td>\n",
              "      <td>-0.030236</td>\n",
              "      <td>-0.046433</td>\n",
              "      <td>-0.014008</td>\n",
              "      <td>0.001793</td>\n",
              "      <td>0.584246</td>\n",
              "      <td>-0.009366</td>\n",
              "      <td>-0.012065</td>\n",
              "      <td>0.001551</td>\n",
              "      <td>-0.014733</td>\n",
              "      <td>-0.001322</td>\n",
              "      <td>-0.031174</td>\n",
              "      <td>0.000350</td>\n",
              "      <td>0.015795</td>\n",
              "      <td>0.012033</td>\n",
              "      <td>0.030941</td>\n",
              "      <td>-0.042688</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.013917</td>\n",
              "      <td>0.004316</td>\n",
              "      <td>0.024638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>touch_screen</th>\n",
              "      <td>-0.010516</td>\n",
              "      <td>0.010061</td>\n",
              "      <td>0.019756</td>\n",
              "      <td>-0.017117</td>\n",
              "      <td>-0.014828</td>\n",
              "      <td>0.016758</td>\n",
              "      <td>-0.026999</td>\n",
              "      <td>-0.002638</td>\n",
              "      <td>-0.014368</td>\n",
              "      <td>0.023774</td>\n",
              "      <td>-0.008742</td>\n",
              "      <td>0.021891</td>\n",
              "      <td>-0.001628</td>\n",
              "      <td>-0.030455</td>\n",
              "      <td>-0.020023</td>\n",
              "      <td>0.012720</td>\n",
              "      <td>0.017196</td>\n",
              "      <td>0.013917</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.011917</td>\n",
              "      <td>-0.040001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wifi</th>\n",
              "      <td>-0.008343</td>\n",
              "      <td>-0.021863</td>\n",
              "      <td>-0.024471</td>\n",
              "      <td>0.022740</td>\n",
              "      <td>0.020085</td>\n",
              "      <td>-0.017620</td>\n",
              "      <td>0.006993</td>\n",
              "      <td>-0.028353</td>\n",
              "      <td>-0.000409</td>\n",
              "      <td>-0.009964</td>\n",
              "      <td>0.005389</td>\n",
              "      <td>0.051824</td>\n",
              "      <td>0.030319</td>\n",
              "      <td>0.022669</td>\n",
              "      <td>0.025929</td>\n",
              "      <td>0.035423</td>\n",
              "      <td>-0.029504</td>\n",
              "      <td>0.004316</td>\n",
              "      <td>0.011917</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price_range</th>\n",
              "      <td>0.149402</td>\n",
              "      <td>0.014001</td>\n",
              "      <td>0.003494</td>\n",
              "      <td>0.009002</td>\n",
              "      <td>0.022464</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.022132</td>\n",
              "      <td>-0.018554</td>\n",
              "      <td>-0.007968</td>\n",
              "      <td>0.031260</td>\n",
              "      <td>0.027628</td>\n",
              "      <td>0.097951</td>\n",
              "      <td>0.116703</td>\n",
              "      <td>0.822354</td>\n",
              "      <td>0.009140</td>\n",
              "      <td>0.035359</td>\n",
              "      <td>0.004394</td>\n",
              "      <td>0.024638</td>\n",
              "      <td>-0.040001</td>\n",
              "      <td>0.014001</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               battery_power      blue  ...      wifi  price_range\n",
              "battery_power       1.000000  0.011252  ... -0.008343     0.149402\n",
              "blue                0.011252  1.000000  ... -0.021863     0.014001\n",
              "clock_speed         0.011482  0.021419  ... -0.024471     0.003494\n",
              "dual_sim           -0.041847  0.035198  ...  0.022740     0.009002\n",
              "fc                  0.033334  0.003593  ...  0.020085     0.022464\n",
              "four_g              0.015665  0.013443  ... -0.017620     0.001001\n",
              "int_memory         -0.004004  0.041177  ...  0.006993     0.022132\n",
              "m_dep               0.034085  0.004049  ... -0.028353    -0.018554\n",
              "mobile_wt           0.001844 -0.008605  ... -0.000409    -0.007968\n",
              "n_cores            -0.029727  0.036161  ... -0.009964     0.031260\n",
              "pc                  0.031441 -0.009952  ...  0.005389     0.027628\n",
              "px_height           0.014901 -0.006872  ...  0.051824     0.097951\n",
              "px_width           -0.008402 -0.041533  ...  0.030319     0.116703\n",
              "ram                -0.000653  0.026351  ...  0.022669     0.822354\n",
              "sc_h               -0.029959 -0.002952  ...  0.025929     0.009140\n",
              "sc_w               -0.021421  0.000613  ...  0.035423     0.035359\n",
              "talk_time           0.052510  0.013934  ... -0.029504     0.004394\n",
              "three_g             0.011522 -0.030236  ...  0.004316     0.024638\n",
              "touch_screen       -0.010516  0.010061  ...  0.011917    -0.040001\n",
              "wifi               -0.008343 -0.021863  ...  1.000000     0.014001\n",
              "price_range         0.149402  0.014001  ...  0.014001     1.000000\n",
              "\n",
              "[21 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(mob.corr())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "ssmiyigjo59C",
        "outputId": "a3d73dd4-982d-4a04-9749-5fd7755da495"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2cf7091190>"
            ]
          },
          "metadata": {},
          "execution_count": 155
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'ram', 'battary_power', 'px_width', 'px_height', 'sc_w'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqgXoStrpZeN",
        "outputId": "9696312b-8d85-4112-dac8-ef529ff7607c"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ram', 'battary_power', 'px_width', 'px_height', 'sc_w')"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_df = mob.corr()"
      ],
      "metadata": {
        "id": "n24QX-8nqmdv"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mob.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5SSmWQbtnic",
        "outputId": "5b781128-3ebc-44fe-bda8-b3aedafa5c60"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr_df = mob.corr()\n",
        "columns = corr_df['price_range'].apply(abs).sort_values(ascending=False)[1:6].index\n",
        "print(columns.values)\n",
        "\n",
        "# ['ram' 'battery_power' 'px_width' 'px_height' 'sc_w']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJjenx2Aqouz",
        "outputId": "d9f7832c-5fe7-4490-a36f-5591ea5f8743"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ram' 'battery_power' 'px_width' 'px_height' 'touch_screen']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ШАГ 2\n",
        "# Теперь необходимо обучить алгоритм.  Для начала разбейте выборку на тестовую и \n",
        "# обучающую, размер тестовой задайте 0.2. Параметр random_state=31. \n",
        "# В качестве модели возьмите логистическую регрессию. \n",
        "# В качестве предикторов возьмите пять ранее отобранных признаков.\n",
        "\n",
        "# Рассчитайте метрику precision, которая покажет, какая доля телефонов, обозначенных классификатором \n",
        "# как дорогие, действительно относится к этой категории. \n",
        "\n",
        "X = mob[columns]\n",
        "y = mob['price_range']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=31)\n",
        "\n",
        "clf = LogisticRegression().fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "6EBalptTqylO"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Задание 3.3. Значение метрики\n",
        "# Введите полученное значение, округлите до четырех знаков после запятой.\n",
        "round(precision_score(y_test, y_pred), 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoX2DCCIwUVM",
        "outputId": "dd5adfd6-a77c-42d6-f754-66a0fc6a2f11"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9859"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zcy-le1jwh-q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "regression_logistic_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}